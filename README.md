# Vision-Based Football Analytics Using YOLO and ByteTrack

**Course:** CS484 Computer Vision
**Institution:** Bilkent University
**Date:** January 2026
**Authors:** Roj Deniz Aldemir, Mustafa Alper Atasoy, Melih Kutay YaÄŸdereli

## Project Overview

This project presents an end-to-end computer vision pipeline designed to transform broadcast football match footage into structured, quantitative statistics. By leveraging state-of-the-art object detection and tracking algorithms, the system automates the extraction of match analytics that are traditionally collected via expensive sensor systems.

The pipeline processes video to detect key entities (players, referees, goalkeepers, ball), tracks them consistently across frames, compensates for camera motion, and maps pixel coordinates to a metric pitch system. The final output includes a fully annotated video overlay and a text-based statistical summary.

## Key Capabilities

* **Dual-Model Object Detection:** Utilizes YOLOv8 for robust detection of medium-to-large entities (players, referees, goalkeepers) and a specialized YOLOv12 model to improve recall for small, fast-moving balls.
* **Multi-Object Tracking:** Implements ByteTrack to associate detections across frames, maintaining stable identities for players and referees despite occlusions.
* **Team Assignment:** separates players into two teams using K-Means clustering (K=2) on extracted jersey color features, with a locking mechanism to prevent label switching.
* **Camera Motion Compensation:** Estimates and removes camera translation using Lucas-Kanade optical flow on static background regions.
* **Perspective Transformation:** Maps 2D pixel positions to a real-world metric coordinate system using a 4-point homography transformation based on field keypoints.
* **Ball Stabilization:** Applies temporal interpolation and outlier rejection to smooth ball trajectories and handle missing detections.
* **Automated Analytics:**
    * **Possession:** Calculates team control percentages based on player-ball proximity.
    * **Passing:** Counts passes by detecting possession transfers between teammates.
    * **Spatial Stats:** Computes total distance covered and generates heatmaps for player activity.
    * **Offside Detection:** Projects a virtual offside line based on the defensive anchor to flag potential offside infractions.

## System Architecture

The analysis pipeline consists of the following sequential modules:

1.  **Input Processing:** Ingestion of standard broadcast video frames (resized to 640x640 for inference).
2.  **Detection & Tracking:**
    * Inference using YOLOv8 (Players) and YOLOv12 (Ball).
    * Track association via ByteTrack.
3.  **Attribute Extraction:**
    * Color feature extraction and clustering for team affiliation.
    * Role assignment (GK, Referee, Player).
4.  **State Estimation:**
    * Optical flow calculation for camera stabilization.
    * Homography transform for metric position estimation.
5.  **Analytics Engine:**
    * Logic-based evaluation of possession, passing, and offside events.
    * Accumulation of distance metrics.
6.  **Output Generation:**
    * Rendering of bounding boxes, trajectories, and HUD overlays.
    * Exporting match analysis reports (TXT) and processed video (MP4).

## Performance

The system was evaluated using a combination of public datasets (Roboflow/Kaggle) and manually curated broadcast clips from major leagues (EPL, Bundesliga, La Liga).

* **Detection:** The YOLOv12 ball-specific model significantly outperformed standard models in recalling small ball objects.
* **Analytics:** Possession and passing statistics generated by the pipeline showed strong correlation with published match data (e.g., computed possession of 30.47% vs. 69.53% matched ground truth trends).
* **Spatial Mapping:** The homography transformation enabled accurate distance estimation and heatmap generation during stable camera segments.

## Installation

### Prerequisites

* Python 3.8+
* NVIDIA GPU (Recommended for inference speed)

### Dependencies

Install the required packages using pip:

```bash
pip install ultralytics opencv-python numpy pandas supervision scikit-learn
```

Usage
Prepare Input: Place your raw match video file (e.g., .mp4) in the input_videos/ directory.

Configure Models: Ensure the trained weights (best.pt for players, best3.pt for ball) are located in the models/ directory.

Run Pipeline:

Bash
```
python main.py
```
The system will generate:

Processed Video: Located in output_videos/, containing visual annotations for tracking, team logic, and possession.

Analysis Report: A text file summarizing possession percentages, pass counts, and physical metrics.

Project Structure
```
main.py: Main entry point for the analysis pipeline.

tracker/: Logic for object detection, ByteTrack integration, and interpolation.

team_assigner/: Modules for color extraction and K-Means clustering.

camera_movement/: Optical flow estimation for camera stabilization.

view_transformer/: Homography matrix calculation and coordinate transformation.

models/: Directory for YOLOv8 and YOLOv12 weight files.

stubs/: Pickle files for caching intermediate tracking data.
```
References
Jocher, G., Chaurasia, A., & Qiu, J. (2023). Ultralytics YOLOv8.

Zhang, Y., et al. (2022). ByteTrack: Multi-Object Tracking by Associating Every Detection Box.

Lucas, B. D., & Kanade, T. (1981). An iterative image registration technique with an application to stereo vision.
